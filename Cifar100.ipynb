{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"GBau6fxK2SxW"},"outputs":[],"source":["#Imports\n","\n","import numpy as np\n","import torch\n","from torchvision import datasets, transforms\n","from torch import nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_gxlsWaYpeFI"},"outputs":[],"source":["# Make a folder for saving model state\n","\n","!mkdir save"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fbj9VInLHYmz"},"outputs":[],"source":["#The CNN Model\n","\n","class CNN(nn.Module):\n","  def __init__(self, lr=0.01, outputSize=100):\n","    super().__init__()\n","    self.CNN = nn.Sequential(\n","        nn.Conv2d(in_channels=3, out_channels=64, kernel_size = 3, stride=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=64, out_channels=128, kernel_size = 3, stride=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=128, out_channels=256, kernel_size = 3, stride=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, stride=2),\n","        nn.Flatten(),\n","        nn.Linear(43264, 10000),\n","        nn.Dropout(p=0.2),\n","        nn.ReLU(),\n","        nn.Linear(10000, 5000),\n","        nn.Dropout(p=0.2),\n","        nn.ReLU(),\n","        nn.Linear(5000, outputSize)\n","    )\n","\n","    self.lr = lr\n","\n","  def forward(self, X):\n","    return self.CNN(X)\n","\n","  def loss(self, y_hat, y):\n","    fn = nn.CrossEntropyLoss()\n","    return fn(y_hat, y)\n","\n","  def configure_optimizers(self):\n","    return torch.optim.SGD(self.parameters())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G9JEhvrV5Dcv"},"outputs":[],"source":["class Trainer:\n","  def __init__(self):\n","    return\n","\n","  def fit_epoch(self): #Single epoch\n","\n","    #Data for monitoring preformance\n","    current_lossT = []\n","    current_lossV = []\n","\n","    for i, data in enumerate(self.dataT): #Triaing\n","        inputs, target = data\n","        inputs = inputs.to(device)#Send to gpu\n","        target = target.to(device)\n","\n","        inputs = inputs.to(torch.float32)\n","        self.optimizer.zero_grad()\n","        outputs = self.model(inputs)\n","        loss = self.model.loss(outputs, target)\n","        #Update model\n","        loss.backward()\n","        self.optimizer.step()\n","\n","        current_lossT.append(loss.item())#Store loss\n","\n","    for i, data in enumerate(self.dataV): #Validation\n","        inputs, target = data\n","        inputs = inputs.to(device)#Send to gpu\n","        target = target.to(device)\n","        inputs = inputs.to(torch.float32)\n","        outputs = self.model(inputs)\n","        loss = self.model.loss(outputs, target)\n","\n","        current_lossV.append(loss.item())#Store loss\n","\n","    #Return average loss for monitoring\n","    return sum(current_lossT) / len(current_lossT), sum(current_lossV) / len(current_lossV)\n","\n","\n","\n","  def fit(self, model, dataT, dataV, path=None):#Trains till validation drops\n","    self.model     = model\n","\n","    if path != None: #Continue models training\n","      self.model.load_state_dict(torch.load(path, weights_only=True))\n","\n","    self.dataT = dataT\n","    self.dataV = dataV\n","\n","    self.optimizer = model.configure_optimizers()#Optimizer\n","\n","    #Tracking loss and Epoch count\n","    EpochCount = 0\n","    TLoss = []\n","    VLoss = []\n","\n","    flag = True\n","    Best = float('inf')\n","\n","    while flag == True:#Flag true when epoches less then max and validation on the fall\n","      tempT, tempV = self.fit_epoch()\n","      TLoss.append(tempT)\n","      VLoss.append(tempV)\n","\n","      if EpochCount+1 >= 10: #max epochs\n","        flag = False\n","      if EpochCount>2: #Stop on Validation as indicator of generalization\n","        if VLoss[EpochCount] > VLoss[EpochCount-1] and VLoss[EpochCount-1] > VLoss[EpochCount-2] and VLoss[EpochCount-2] > VLoss[EpochCount-3]:\n","          flag = False\n","\n","      print(\"epoch: \" + str(EpochCount+1) + \" ValLoss: \" + str(VLoss[EpochCount]))\n","\n","\n","      #Save best model and latest model\n","      if tempV < Best:\n","        print(\"Lowest loss yet!!\")\n","        Best = tempV\n","        torch.save(self.model.state_dict(), \"/content/save/best\")\n","\n","      torch.save(self.model.state_dict(), \"/content/save/last\")\n","      EpochCount +=1\n","    return TLoss, VLoss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7XsN9ARe4OZX"},"outputs":[],"source":["\n","class Tester:#Prints test outcomes\n","\n","  def __init__(self):\n","    return\n","\n","  def Test(self, model, data, load):\n","      self.model = model\n","      self.dataT = data\n","      self.model.load_state_dict(torch.load(load, weights_only=True))#load instance of model\n","\n","      right = 0\n","      wrong = 0\n","\n","      for i, data in enumerate(self.dataT):\n","          inputs, target = data\n","          inputs = inputs.to(device)#send to gpu\n","          target = target.to(device)\n","          inputs = inputs.to(torch.float32)\n","          outputs = self.model(inputs)\n","\n","          indices = torch.max(outputs, 1).indices\n","          outputs = outputs.cpu().detach().numpy()\n","\n","          #Tally hits and misses\n","          if indices==target:\n","            right+=1\n","          else:\n","            wrong+=1\n","\n","\n","\n","      total = 0\n","      accuracy = right / (right + wrong)\n","      print(\"accuracy: \" + str(accuracy))\n","\n","      #The following can be uncommented if the results on a class basis are needed\n","      #for c in range(100):\n","        #print(\"class: \" + str(c) + \"Accuracy: \" + str((classes_right[c]/50)*100))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAYAll6Pf8QE"},"outputs":[],"source":["#Dataset\n","train = datasets.CIFAR100('./data/', train=True, download=True, transform=transforms.ToTensor())\n","temp = datasets.CIFAR100('./data/', train=False, download=True, transform=transforms.ToTensor())\n","\n","#Split is (Train : 500 (83.3%)) (Validate : 50 (8.3%)) (Test : 50 (8.3%)) for each class\n","test = []\n","validate = []\n","array = np.zeros(100)\n","\n","for data in temp:\n","  if array[data[1]] < 50:\n","    test.append(data)\n","    array[data[1]] += 1\n","  else:\n","    validate.append(data)\n","\n","#Final datasets\n","dl_train = torch.utils.data.DataLoader(dataset=train, batch_size=10, shuffle=True)\n","dl_test = torch.utils.data.DataLoader(dataset=test, batch_size=1, shuffle=True)\n","dl_validate = torch.utils.data.DataLoader(dataset=validate, batch_size=1, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgJcTkGy81Bt"},"outputs":[],"source":["#Creates and trains Model\n","\n","device  = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","mlp_model = CNN(lr=0.01).to(device)\n","trainer = Trainer()\n","\n","\n","#Create new Model\n","TLoss, VLoss = trainer.fit(mlp_model, dl_train, dl_validate)\n","\n","#Or load Model to continue training\n","#TLoss, VLoss = trainer.fit(mlp_model, dl_train, dl_validate, \"example_path\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k7jpvX2OhMAe","collapsed":true},"outputs":[],"source":["#Ploting loss\n","import matplotlib.pyplot as plt\n","\n","plt.plot(TLoss, label = \"Training Loss\")\n","plt.plot(VLoss, label = \"Validation Loss\")\n","plt.title(\"Loss visualization\")\n","plt.xlabel(\"Epoch Count\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9VgEUFJuOg8I","collapsed":true},"outputs":[],"source":["#Tests Model on unseen data\n","\n","#Data presentation can be configured in the Tester Class\n","\n","Tester = Tester()\n","\n","Tester.Test(mlp_model, dl_test, \"/content/save/d\")"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1NikGRbwVR563gF3I-vDU_QtqaWrKAOED","timestamp":1742012272861}],"authorship_tag":"ABX9TyNUA7674gHjOxf1nbTekzks"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}